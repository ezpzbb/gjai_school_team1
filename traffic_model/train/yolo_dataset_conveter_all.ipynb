{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7da360-82c1-4de1-8a03-7b264f2bf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import shutil\n",
    "from typing import Any, Dict, List, Optional, Set, Tuple\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f817b15-a256-4e3a-aac6-fa29151097ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습(train) 세트 경로\n",
    "TRAIN_ROOT: Path = Path(\"dataset/traffic_data/training/bbox_tr\")\n",
    "TRAIN_LABEL_DIR: Path = TRAIN_ROOT / \"label_bbox\"\n",
    "TRAIN_IMAGE_DIR: Path = TRAIN_ROOT / \"image_bbox\"\n",
    "\n",
    "# 검증(val) 세트 경로\n",
    "VAL_ROOT: Path = Path(\"dataset/traffic_data/validation/bbox_val\")\n",
    "VAL_LABEL_DIR: Path = VAL_ROOT / \"label_bbox\"\n",
    "VAL_IMAGE_DIR: Path = VAL_ROOT / \"image_bbox\"\n",
    "\n",
    "# 출력 루트\n",
    "OUT_ROOT: Path = Path(\"yolo_transfer_all\")\n",
    "\n",
    "# 실행 옵션\n",
    "OVERWRITE_LABELS: bool = True\n",
    "COPY_IMAGES: bool = True\n",
    "DRY_RUN: bool = False\n",
    "\n",
    "# 카테고리 통합 규칙\n",
    "TARGET_CLASS_ORDER: List[str] = [\n",
    "    \"승용차\",\n",
    "    \"버스\",\n",
    "    \"트럭\",\n",
    "    \"오토바이(자전거)\",\n",
    "    \"분류없음\"\n",
    "]\n",
    "\n",
    "MERGE_TO: Dict[str, str] = {\n",
    "    \"소형버스\": \"버스\",\n",
    "    \"대형버스\": \"버스\"\n",
    "}\n",
    "\n",
    "DROP_SET: Set[str] = {\n",
    "    \"대형 트레일러\",\n",
    "    \"대형트레일러\",\n",
    "    \"보행자\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d9c335-46bc-46b1-abca-fe375a6875f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(path: Path) -> None:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def build_camera_index(images_root: Path) -> Dict[str, List[Path]]:\n",
    "    cam_index: Dict[str, List[Path]] = {}\n",
    "    if not images_root.exists():\n",
    "        return cam_index\n",
    "    for site1 in images_root.iterdir():\n",
    "        if not site1.is_dir():\n",
    "            continue\n",
    "        for site2 in site1.iterdir():\n",
    "            if not site2.is_dir():\n",
    "                continue\n",
    "            for cam_dir in site2.iterdir():\n",
    "                if cam_dir.is_dir():\n",
    "                    cam_index.setdefault(cam_dir.name, []).append(cam_dir)\n",
    "    return cam_index\n",
    "\n",
    "def find_image_path_from_index(cam_index: Dict[str, List[Path]], camera_id: str, filename: str) -> Optional[Path]:\n",
    "    for d in cam_index.get(camera_id, []):\n",
    "        candidate = d / filename\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911221f3-8ff7-4dc5-9b27-469aa6b67fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyxy_to_yolo(x1: float, y1: float, x2: float, y2: float, w: int, h: int) -> Tuple[float, float, float, float]:\n",
    "    x1c = float(min(max(x1, 0.0), float(w)))\n",
    "    y1c = float(min(max(y1, 0.0), float(h)))\n",
    "    x2c = float(min(max(x2, 0.0), float(w)))\n",
    "    y2c = float(min(max(y2, 0.0), float(h)))\n",
    "    xmin, xmax = min(x1c, x2c), max(x1c, x2c)\n",
    "    ymin, ymax = min(y1c, y2c), max(y1c, y2c)\n",
    "    bw, bh = max(xmax - xmin, 1e-6), max(ymax - ymin, 1e-6)\n",
    "    cx, cy = xmin + bw / 2.0, ymin + bh / 2.0\n",
    "    return cx / w, cy / h, bw / w, bh / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd725d5-769d-440a-a7f0-778a264caa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3단계 분류 제거 → 항상 단일 폴더 all_data 사용\n",
    "def decide_stage(weather: str, time_space: str) -> str:\n",
    "    return \"all_data\"\n",
    "\n",
    "\n",
    "def process_coco_json_fixed_subset(\n",
    "    json_path: Path,\n",
    "    cam_index: Dict[str, List[Path]],\n",
    "    out_root: Path,\n",
    "    id_to_idx: Dict[int, int],\n",
    "    overwrite_labels: bool,\n",
    "    copy_images: bool,\n",
    "    dry_run: bool,\n",
    "    subset_name: str\n",
    ") -> Dict[str, int]:\n",
    "    counts = {\"copied\": 0, \"labeled\": 0, \"missing_image\": 0}\n",
    "\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        coco_any: Any = json.load(f)\n",
    "\n",
    "    meta_by_id = {int(m[\"id\"]): m for m in coco_any.get(\"meta\", [])}\n",
    "    images = list(coco_any.get(\"images\", []))\n",
    "    anns = list(coco_any.get(\"annotations\", []))\n",
    "\n",
    "    anns_by_image: Dict[int, List[Dict[str, Any]]] = {}\n",
    "    for ann in anns:\n",
    "        anns_by_image.setdefault(int(ann[\"image_id\"]), []).append(ann)\n",
    "\n",
    "    # 단일 폴더 all_data 생성\n",
    "    ensure_dir(out_root / \"all_data\" / subset_name / \"images\")\n",
    "    ensure_dir(out_root / \"all_data\" / subset_name / \"labels\")\n",
    "\n",
    "    for img in images:\n",
    "        img_id = int(img[\"id\"])\n",
    "        meta_id = int(img[\"meta_id\"])\n",
    "        file_name = str(img[\"file_name\"])\n",
    "\n",
    "        camera_id = file_name.split(\"/\")[0]\n",
    "        fname = file_name.split(\"/\")[-1]\n",
    "\n",
    "        src_path_opt = find_image_path_from_index(cam_index, camera_id, fname)\n",
    "        if src_path_opt is None or not src_path_opt.exists():\n",
    "            counts[\"missing_image\"] += 1\n",
    "            continue\n",
    "        src_path = src_path_opt\n",
    "\n",
    "        dst_img_dir = out_root / \"all_data\" / subset_name / \"images\" / camera_id\n",
    "        dst_lbl_dir = out_root / \"all_data\" / subset_name / \"labels\" / camera_id\n",
    "        ensure_dir(dst_img_dir)\n",
    "        ensure_dir(dst_lbl_dir)\n",
    "\n",
    "        dst_img_path = dst_img_dir / fname\n",
    "        dst_lbl_path = dst_lbl_dir / (Path(fname).stem + \".txt\")\n",
    "\n",
    "        with Image.open(src_path) as im:\n",
    "            w, h = im.size\n",
    "\n",
    "        lines: List[str] = []\n",
    "        for ann_item in anns_by_image.get(img_id, []):\n",
    "            bboxes = [list(map(float, b)) for b in ann_item.get(\"bbox\", [])]\n",
    "            cat_ids = [int(c) for c in ann_item.get(\"category_id\", [])]\n",
    "            for b, c in zip(bboxes, cat_ids):\n",
    "                if c not in id_to_idx:\n",
    "                    continue\n",
    "                x1, y1, x2, y2 = b\n",
    "                cxn, cyn, wn, hn = xyxy_to_yolo(x1, y1, x2, y2, w, h)\n",
    "                cls_idx = id_to_idx[c]\n",
    "                lines.append(f\"{cls_idx} {cxn:.6f} {cyn:.6f} {wn:.6f} {hn:.6f}\")\n",
    "\n",
    "        if not dry_run:\n",
    "            if overwrite_labels or not dst_lbl_path.exists():\n",
    "                with open(dst_lbl_path, \"w\", encoding=\"utf-8\") as lf:\n",
    "                    lf.write(\"\\n\".join(lines))\n",
    "            if copy_images and not dst_img_path.exists():\n",
    "                shutil.copy2(src_path, dst_img_path)\n",
    "        counts[\"labeled\"] += 1\n",
    "        if copy_images:\n",
    "            counts[\"copied\"] += 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914d449-661b-418e-9be0-1adda51d037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_category_maps(first_json_path: Path) -> Tuple[Dict[int, int], Dict[int, str]]:\n",
    "    with open(first_json_path, \"r\", encoding=\"utf-8\") as f0:\n",
    "        first_any: Any = json.load(f0)\n",
    "    categories: List[Dict[str, Any]] = list(first_any.get(\"categories\", []))\n",
    "\n",
    "    name_to_id = {str(cat[\"name\"]): int(cat[\"id\"]) for cat in categories}\n",
    "    target_index_of = {name: i for i, name in enumerate(TARGET_CLASS_ORDER)}\n",
    "\n",
    "    id_to_idx: Dict[int, int] = {}\n",
    "    for cname, cid in name_to_id.items():\n",
    "        if cname in DROP_SET:\n",
    "            continue\n",
    "        final_name = MERGE_TO.get(cname, cname)\n",
    "        if final_name not in target_index_of:\n",
    "            continue\n",
    "        id_to_idx[cid] = target_index_of[final_name]\n",
    "\n",
    "    id_to_name = {idx: name for name, idx in target_index_of.items()}\n",
    "    return id_to_idx, id_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59dc69-a877-4c8e-9dac-7f1d9cadf487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline() -> Dict[str, int]:\n",
    "    ensure_dir(OUT_ROOT)\n",
    "    train_cam_index = build_camera_index(TRAIN_IMAGE_DIR)\n",
    "    val_cam_index = build_camera_index(VAL_IMAGE_DIR)\n",
    "\n",
    "    train_json_files = sorted(TRAIN_LABEL_DIR.rglob(\"*.json\"))\n",
    "    val_json_files = sorted(VAL_LABEL_DIR.rglob(\"*.json\"))\n",
    "    if not train_json_files or not val_json_files:\n",
    "        raise FileNotFoundError(\"Train/Val JSON missing.\")\n",
    "\n",
    "    id_to_idx, id_to_name = build_category_maps(train_json_files[0])\n",
    "    total = {\"copied\": 0, \"labeled\": 0, \"missing_image\": 0}\n",
    "\n",
    "    for jp in tqdm(train_json_files, desc=\"train json files\"):\n",
    "        c = process_coco_json_fixed_subset(\n",
    "            json_path=jp,\n",
    "            cam_index=train_cam_index,\n",
    "            out_root=OUT_ROOT,\n",
    "            id_to_idx=id_to_idx,\n",
    "            overwrite_labels=OVERWRITE_LABELS,\n",
    "            copy_images=COPY_IMAGES,\n",
    "            dry_run=DRY_RUN,\n",
    "            subset_name=\"train\"\n",
    "        )\n",
    "        for k in total.keys():\n",
    "            total[k] += c[k]\n",
    "\n",
    "    for jp in tqdm(val_json_files, desc=\"val json files\"):\n",
    "        c = process_coco_json_fixed_subset(\n",
    "            json_path=jp,\n",
    "            cam_index=val_cam_index,\n",
    "            out_root=OUT_ROOT,\n",
    "            id_to_idx=id_to_idx,\n",
    "            overwrite_labels=OVERWRITE_LABELS,\n",
    "            copy_images=COPY_IMAGES,\n",
    "            dry_run=DRY_RUN,\n",
    "            subset_name=\"val\"\n",
    "        )\n",
    "        for k in total.keys():\n",
    "            total[k] += c[k]\n",
    "\n",
    "    yaml_path = OUT_ROOT / \"all_data\" / \"data.yaml\"\n",
    "    ensure_dir(yaml_path.parent)\n",
    "    idx_names = [v for _, v in sorted(id_to_name.items())]\n",
    "    with open(yaml_path, \"w\", encoding=\"utf-8\") as yf:\n",
    "        yf.write(\n",
    "            f\"path: {OUT_ROOT / 'all_data'}\\n\"\n",
    "            f\"train: train/images\\n\"\n",
    "            f\"val: val/images\\n\"\n",
    "            f\"nc: {len(idx_names)}\\n\"\n",
    "            f\"names: {idx_names}\\n\"\n",
    "        )\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17014662-cca7-48cd-aeb7-e84a0964357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = run_pipeline()\n",
    "\n",
    "print(\"Done\")\n",
    "print(f\"copied -> {summary.get('copied', 0)}\")\n",
    "print(f\"labeled -> {summary.get('labeled', 0)}\")\n",
    "print(f\"missing_image -> {summary.get('missing_image', 0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
